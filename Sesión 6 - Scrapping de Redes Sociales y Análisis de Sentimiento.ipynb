{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sesión 6\n",
    "## Scrapping de Redes Sociales y Análisis de Sentimiento\n",
    "\n",
    "### Caso: McDonald's \n",
    "#### ¿Qué piensan los clientes de mi empresa/producto?\n",
    "\n",
    "##### Contenido\n",
    "\n",
    "1. Presentación del Caso\n",
    "    * Motivación (Problemática y Estadísticas)\n",
    "    * Objetivo\n",
    "2. Desarrollo del Notebook\n",
    "    * Preprocesamiento de Datos\n",
    "    * Análisis Exploratorio\n",
    "    * Modelado\n",
    "3. Análisis de Resultados\n",
    "    * Métricas de Evaluación\n",
    "    * Insights\n",
    "    * Oportunidades\n",
    "4. Planeamiento para medición de acciones y resultados\n",
    "    * Cómo medir acciones y resultados cuando el modelo sea utilizado\n",
    "5. Toma de acciones y reconomiento de nueva metricas\n",
    "    * Definición de acciones que debemos tomar con los resultados obtenidos y evaluar nuevas oportunidades para obtención de métricas y datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentación del Caso\n",
    "\n",
    "## Motivación\n",
    "\n",
    "### Problemática\n",
    "\n",
    "Las empresas, sin importar su tamaño, están expuestas a la opinión del público, sea buena o mala. En la actualidad, uno de los canales de comunicacion y publicacion de estas opiniones son las redes sociales.\n",
    "\n",
    "![3.2-mil-millones-usuarios](https://bit.ly/37BuWxg) | ![generations](https://bit.ly/38xguHW)\n",
    "---|---\n",
    "\n",
    "Por este motivo las diferentes redes sociales (como facebook, instagram, youtube, twitter, etc) ofrecen una sección de analytics para las empresas o perfiles de influencers.\n",
    "\n",
    "![54-busca-prod](https://bit.ly/2vA71RD) | ![71-impacto](https://bit.ly/2HtvWJt)\n",
    "---|---\n",
    "\n",
    "\n",
    "Sin embargo, el nivel de detalle es descriptivo y no ofrece análisis más avanzados, como por ejemplo el sentimiento de cada uno de las interacciones (comentarios, twits, etc.). \n",
    "\n",
    "![sentiment-scale](https://bit.ly/2OZjDZq)\n",
    "\n",
    "Este conocimiento profundo de la relación con los clientes puede ser determinante para tomar decisiones de negocio que permitan diferenciarte de la competencia y alcanzar los objetivos de la empresa.\n",
    "\n",
    "![social-media-dashboard](https://bit.ly/39D8Ls2)\n",
    "\n",
    "Asimismo, las empresas pueden monitorear su presencia en redes sociales y poner objetivos de \"engagment\" o \"affinity\" con sus usuarios. El alto uso de redes sociales permite medir estos y otros indicadores en tiempo real. Por ejemplo, en tiempos de crisis, es posible evaluar la efectividad de las estrategias de mejora de imagen/posicionamiento de marca. En ese sentido, hoy evaluaremos las redes sociales de McDonald's una empresa que recientemente ha pasado por una crisis muy fuerte relacionada a un lamentable hecho en las instalaciones de una de sus franquicias.\n",
    "\n",
    "## Objetivo de la Sesión\n",
    "\n",
    "Realizar el análisis de las redes sociales de McDonalds, este objetivo lo dividiremos en las siguientes tareas:\n",
    "\n",
    "- Obtención de datos\n",
    "- Cálculo de indicadores simples\n",
    "- Análisis de sentimiento\n",
    "\n",
    "Finalmente, obtener algunos insights apartir del análisis realizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manos a la obra\n",
    "\n",
    "## Primero importaremos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # Herramienta de web scrapping\n",
    "\n",
    "import requests # Herramienta para consultar paginas web\n",
    "\n",
    "import pandas as pd # Herramienta de manipulacion de datos (reemplaza a excel)\n",
    "\n",
    "import random # Generación de números aleatorios\n",
    "\n",
    "from datetime import datetime # Herramienta para trabajar con fechas\n",
    "\n",
    "# Herramienta de visualizacion de datos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Para texto\n",
    "import re # Herramienta para expresiones regulares\n",
    "from nltk.corpus import stopwords # Herramienta de procesamiento de lenguaje natural\n",
    "!pip install unidecode\n",
    "from unidecode import unidecode # Traduce caracateres especiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\", color_codes=True) # Estilo de gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline # Visualizar los gráficos dentro del notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención de datos\n",
    "\n",
    "Existen diversas formas de obtener datos de redes sociales. En el caso más simple, se pueden descargar los datos de tu propia página en la sección de datos o analytics. Sin embargo, muchas veces es necesario obtener más datos de los que se entregan en estos servicios predeterminados. Asimismo, si deseas realizar una comparación entre marcas o empresas es necesario obtener los datos mediante otro método. \n",
    "\n",
    "![scrapping-process](https://i.imgur.com/zrMPtRi.png)\n",
    "\n",
    "En ese sentido, el método de Web Scraping permite la recopilación automática de grandes cantidades de información de sitios web para su posterior análisis.\n",
    "\n",
    "![web-example](https://i.imgur.com/VSjetX1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acontinuación vamos a extraer la fecha de un post en Facebook\n",
    "\n",
    "... Esto lo haremos a modo de ejemplo debido a que extraer todo el contenido que necesitamos para el análisis tomaría mucho tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL que vamos a scrappear\n",
    "url_post = 'https://www.facebook.com/McDonaldsPeru/photos/a.173819762664531/2626129120766904/?type=3&theater'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solicitud del codigo fuente de la url\n",
    "post_source_html = requests.get(url_post)\n",
    "post_source_html.ok # Validamos si recibimos todo correcto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Herramienta para procesar archivos html\n",
    "soup_photo = BeautifulSoup(post_source_html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos segun las etiquetas y los atributos de las mismas para obtener la fecha de publicación\n",
    "post_date = soup_photo.find(\"span\", attrs={\"class\":\"timestampContent\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos la fecha obtenida\n",
    "post_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora que ya vimos un ejemplo de como extraer los datos web, usaremos un archivo de datos previamente generado para hacer el análisis con mayor detalle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fb_comments = pd.read_csv('https://raw.githubusercontent.com/Claudio9701/web-scraping-sentiment-analysis/master/fb_comments_mcdo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fb_comments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fb_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora calculemos el sentimiento de estos comentarios \n",
    "\n",
    "Debemos seguir los siguientes pasos:\n",
    "\n",
    "1. Obtener un **diccionario de palabras positivas y negativas**\n",
    "2. **Limpiar** las palabras del diccionario y los comentarios\n",
    "4. Calcular el **numero de palabras asociadas a cada sentimiento** por comentario\n",
    "6. **Visualizar** el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos las palabras y su sentimiento\n",
    "words_sentiment = pd.read_csv('https://raw.githubusercontent.com/Claudio9701/web-scraping-sentiment-analysis/master/words_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos informacion general de los datos\n",
    "words_sentiment.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos un vistazo de las primeras 5 filas de los datos\n",
    "words_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos las palabras del diccionario\n",
    "words_sentiment['word'] = words_sentiment['word'].apply(unidecode) # Elimina caracteres especiales\n",
    "words_sentiment['word'] = words_sentiment['word'].str.lower() # Pone todo en minusculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de palabras positivas\n",
    "pos_words = words_sentiment[words_sentiment['sentiment'] == 'positive']\n",
    "pos_words = pos_words['word'].values.tolist()\n",
    "\n",
    "# Lista de palabras negativas\n",
    "neg_words = words_sentiment[words_sentiment['sentiment'] == 'negative']\n",
    "neg_words = neg_words['word'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora seleccionaremos un comentario como ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_fb_comments.loc[20,'comment_text']\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos el comentario\n",
    "text_ = unidecode(text) # Elimina caracateres especiales\n",
    "text_ = re.sub(\"[^ a-zA-Z]\", \"\", text_) # Elimina puntuacion y otros\n",
    "text_ = text_.lower() # Pone todo en minúsculas\n",
    "print(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text_.split(\" \") # Separa las palabras por espacios -> lista de tokens            \n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obten las palabras stopwords\n",
    "stopwords_set = set(stopwords.words(\"spanish\")) \n",
    "# Eliminamos las palabras stopwords\n",
    "clean_words = [t for t in tokens if not t in stopwords_set]\n",
    "print(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo de palabras positivas y negativas\n",
    "pos_word_count = 0\n",
    "neg_word_count = 0\n",
    "\n",
    "for word in clean_words:\n",
    "    if word in pos_words:\n",
    "        pos_word_count += 1\n",
    "    if word in neg_words:\n",
    "        neg_word_count += 1\n",
    "\n",
    "print('# de palabras positivas: ', pos_word_count)\n",
    "print('# de palabras negativas: ', neg_word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora haremos el procedimiento para todos los comentarios ...\n",
    "... para hacer esto mas simple utilizaremos funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Eliminar caracteres que no sean a-z y A-Z => https://regexr.com/\n",
    "    text_ = unidecode(text)\n",
    "    text_ = re.sub(\"[^ a-zA-Z]\", \"\", text_)\n",
    "    text_ = text_.lower()\n",
    "    \n",
    "    # Tokeniza el texto\n",
    "    tokens = text_.split(\" \")              \n",
    "    \n",
    "    # Obtenemos la lista de stopwords\n",
    "    stopwords_set = set(stopwords.words(\"spanish\"))\n",
    "    \n",
    "    # Eliminamos las palabras stopwords del texto\n",
    "    clean_words = [token for token in tokens if not token in stopwords_set]\n",
    "    \n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text, pos_words, neg_words):\n",
    "    # Conteo de palabras positivas y negativas\n",
    "    pos_word_count = 0\n",
    "    neg_word_count = 0\n",
    "    \n",
    "    for word in text:\n",
    "        if word in pos_words:\n",
    "            pos_word_count += 1\n",
    "        if word in neg_words:\n",
    "            neg_word_count += 1\n",
    "            \n",
    "    if (pos_word_count - neg_word_count) == 0:\n",
    "        sentiment = 'neutro'\n",
    "    if (pos_word_count - neg_word_count) > 0:\n",
    "        sentiment = 'positive'\n",
    "    if (pos_word_count - neg_word_count) < 0:\n",
    "        sentiment = 'negative'\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos todos los comentarios\n",
    "clean_comments = df_fb_comments['comment_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculamos el sentimiento para todos los comentarios\n",
    "comment_sentiment = clean_comments.apply(func=get_sentiment,\n",
    "                                         pos_words=pos_words,\n",
    "                                         neg_words=neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Contamos el numero de comentario por tipo de sentimiento\n",
    "comment_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la proporcion (~porcentaje) de comentarios por tipo de sentimiento\n",
    "comment_sentiment.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podemos visualizar facilmente nuestros resultados utilizando librerias como matplotlib, seaborn, plotly, entre otras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizacion de los resultados en un grafico de pie\n",
    "sent_props = comment_sentiment.value_counts(normalize=True) \n",
    "sent_props.plot.pie()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ya realizamos el trabajo duro!\n",
    "\n",
    "... Sin embargo, sabemos que existen muchos casos especiales que no hemos considerado, no estamos seguros de que tenemos todas las palabras posibles (de hecho podemos comprobarlo). Entonces, ¿Qué podemos hacer? \n",
    "\n",
    "### No reinventemos la rueda..\n",
    "\n",
    "Una búsqueda rápida de lo que queremos hacer puede ahorrarnos horas de desarrollo al encontrar una o más herramientas que ya están listas para usar.\n",
    "\n",
    "En este caso **hemos encontrado en Github a [senti-py](https://github.com/aylliote/senti-py) un clasificador pre-entrenado de análisis de sentimiento en español**, que ya tiene implementado una serie de pasos de **limpieza de texto en español** y esta **entrenado en un enorme corpus de texto en español** de diversas fuentes online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la libreria\n",
    "!pip install spanish_sentiment_analysis\n",
    "from classifier import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instaciamos el modelo de clasificación\n",
    "clf = SentimentClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recordemos el texto de ejemplo\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la clasificacion con el método \"predict\"\n",
    "clf.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora lo aplicamos a todos los comentarios\n",
    "new_sentiment = df_fb_comments['comment_text'].apply(clf.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debido a que la clasificacion es en valores continuos \n",
    "# podemos visualizar la distribución de los datos en un histograma\n",
    "new_sentiment.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.distplot(new_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para simplificar el analisis definiremos 3 rangos de sentimiento\n",
    "labels = ['negative','neutro','positive']\n",
    "bins = [-0.1, 0.4, 0.6, 1.1]\n",
    "new_sentiment_cat = pd.cut(new_sentiment, bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de los resultados en un gráfico de pie\n",
    "new_sent_props = new_sentiment_cat.value_counts(normalize=True)\n",
    "# Utilicemos el mismo orden que en el gráfico de pie anterior\n",
    "new_sent_props = new_sent_props[['neutro', 'positive','negative']]\n",
    "new_sent_props.plot.pie()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizemos más a fondo cada categoría\n",
    "Existen otras posibilidades de visualización cuando se tratan de datos texuales como por ejemplo una **nube de palabras** frecuentes.\n",
    "\n",
    "### Nubes de palabras\n",
    "Este tipo de visualización te permite tener un vistazo rápido de cuales son **las palabras más usadas** con respecto a un tópico o en este caso con respecto a un sentimiento.\n",
    "\n",
    "### Ahora realizaremos una nubbe de palabras para cada categoria de sentimiento.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los comentarios en cada categoría\n",
    "positive_texts = df_fb_comments['comment_text'][new_sentiment_cat=='positive']\n",
    "neutral_texts = df_fb_comments['comment_text'][new_sentiment_cat=='neutro']\n",
    "negative_texts = df_fb_comments['comment_text'][new_sentiment_cat=='negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la librería\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones de ayuda para darle color a las nubes\n",
    "\n",
    "def red_color_func(word, font_size, position, orientation, random_state=None,\n",
    "                    **kwargs):\n",
    "    return f'hsl({random.randint(350,360)}, {random.randint(40, 100)}%, {random.randint(50, 100)}%)'\n",
    "\n",
    "\n",
    "def green_color_func(word, font_size, position, orientation, random_state=None,\n",
    "                    **kwargs):\n",
    "    return f'hsl({random.randint(100,130)}, {random.randint(40, 100)}%, {random.randint(50, 100)}%)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une todos los comentarios en un solo texto (formato de la librería)\n",
    "positive_words =' '.join([text for text in positive_texts]) \n",
    "\n",
    "# Se contruye la nuba de palabras\n",
    "wordcloud = WordCloud(\n",
    "    background_color='rgba(255,255,255,0)', mode='RGBA',\n",
    "    width=1800, height=1400,\n",
    "    stopwords=set(stopwords.words(\"spanish\"))\n",
    ").generate(positive_words)\n",
    "# Le damos color a las palabras\n",
    "wordcloud.recolor(color_func=green_color_func, random_state=3)\n",
    "\n",
    "# Utilizamos matplotlib para visualizar la imagen generada\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une todos los comentarios en un solo texto (formato de la librería)\n",
    "negative_words =' '.join([text for text in negative_texts])\n",
    "\n",
    "# Se contruye la nuba de palabras\n",
    "wordcloud = WordCloud(\n",
    "    background_color='rgba(255,255,255,0)', mode='RGBA',\n",
    "    width=1800, height=1400,\n",
    "    stopwords=set(stopwords.words(\"spanish\"))\n",
    ").generate(negative_words)\n",
    "# Le damos color a las palabras\n",
    "wordcloud.recolor(color_func=red_color_func, random_state=3)\n",
    "\n",
    "# Utilizamos matplotlib para visualizar la imagen generada\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une todos los comentarios en un solo texto (formato de la librería)\n",
    "neutral_words =' '.join([text for text in neutral_texts])\n",
    "\n",
    "# Se contruye la nuba de palabras\n",
    "wordcloud = WordCloud(\n",
    "    background_color='rgba(255,255,255,0)', mode='RGBA',\n",
    "    width=1800, height=1400,\n",
    "    stopwords=set(stopwords.words(\"spanish\"))\n",
    ").generate(neutral_words)\n",
    "\n",
    "# Utilizamos matplotlib para visualizar la imagen generada\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tambien podemos utilizar variables temporales para hacer un monitoreo del sentimiento en diferentes fechas ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos la columna sentimiento\n",
    "df_fb_comments['sent-py_sentiment'] = new_sentiment\n",
    "df_fb_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamos por fecha\n",
    "df_fb_comments.groupby('post_date').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos el sentimiento promedio por día\n",
    "df_fb_comments.groupby('post_date').mean()['sent-py_sentiment'].plot.line(style='-o')\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylabel('Mean sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos el número de comentarios por día\n",
    "df_fb_comments.groupby('post_date').count()['sent-py_sentiment'].plot.line(style='-o')\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylabel('Numero de comentarios')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué insights podemos obtener de este análisis?\n",
    "\n",
    "1. Revisa los resultados\n",
    "2. Encuentra relaciones\n",
    "3. Define acciones\n",
    "\n",
    "### ¡Hagámoslo juntos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (curso-mkt)",
   "language": "python",
   "name": "cursomkt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
